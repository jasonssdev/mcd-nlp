{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "d302c577",
      "cell_type": "markdown",
      "source": "# Tarea NLP — Exploración, Preprocesamiento, TF‑IDF y Clasificación\n\nEste notebook responde a las preguntas solicitadas usando los archivos:\n\n- `df_train.csv`\n- `df_test.csv`\n\n> **Nota sobre NLTK**: para evitar dependencias de descargas (stopwords/punkt/wordnet), el preprocesamiento usa `stop_words='english'` de **scikit‑learn**, que es estándar en pipelines TF‑IDF.\n",
      "metadata": {}
    },
    {
      "id": "cd57e9a2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n\n# Paths (ajusta si cambias la ubicación de los archivos)\nTRAIN_PATH = \"df_train.csv\"\nTEST_PATH  = \"df_test.csv\"\n\ntrain = pd.read_csv(TRAIN_PATH)\ntest  = pd.read_csv(TEST_PATH)\n\nprint(\"train shape:\", train.shape)\nprint(\"test  shape:\", test.shape)\ntrain.head()",
      "outputs": []
    },
    {
      "id": "d928ddfd",
      "cell_type": "markdown",
      "source": "## 1) Concatenar ambos conjuntos de datos (mirada general)\n\nConcatenamos **train + test** en un solo DataFrame (`df_all`) para explorar distribución de clases, largos de oraciones y frecuencia de palabras.\n",
      "metadata": {}
    },
    {
      "id": "7a7a67d4",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "df_all = pd.concat([train.assign(split=\"train\"), test.assign(split=\"test\")], ignore_index=True)\ndf_all[['split','label','tweet']].head()",
      "outputs": []
    },
    {
      "id": "01581199",
      "cell_type": "markdown",
      "source": "### Funciones auxiliares de limpieza y tokenización\n\n- Se remueven **URLs**, **@mentions** y entidades HTML del tipo `&#12345;`\n- Se dejan solo letras y apóstrofes (por ejemplo, `don't`, `i'm`)\n- Se pasa a minúsculas\n- Para análisis de palabras, se filtran **stopwords** y tokens muy cortos (`len <= 2`)\n",
      "metadata": {}
    },
    {
      "id": "a584cbe0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "url_re = re.compile(r'https?://\\S+|www\\.\\S+')\nmention_re = re.compile(r'@\\w+')\nhtml_entity_re = re.compile(r'&#\\d+;')\nnonword_re = re.compile(r\"[^a-zA-Z'\\s]+\")\n\ndef clean_text_basic(s: str) -> str:\n    s = str(s)\n    s = url_re.sub(' ', s)\n    s = mention_re.sub(' ', s)\n    s = html_entity_re.sub(' ', s)\n    s = nonword_re.sub(' ', s)\n    s = re.sub(r'\\s+', ' ', s).strip().lower()\n    return s\n\ndef tokenize_words(s: str):\n    s = clean_text_basic(s)\n    toks = re.findall(r\"[a-zA-Z']+\", s)\n    toks = [t for t in toks if (t not in ENGLISH_STOP_WORDS and len(t) > 2)]\n    return toks\n\ndef count_words(s: str) -> int:\n    s = clean_text_basic(s)\n    return len(re.findall(r\"[a-zA-Z']+\", s))\n\ndf_all['tweet_clean'] = df_all['tweet'].map(clean_text_basic)\ndf_all['n_words'] = df_all['tweet'].map(count_words)\n\ndf_all[['tweet','tweet_clean','n_words']].head()",
      "outputs": []
    },
    {
      "id": "dcf7397b",
      "cell_type": "markdown",
      "source": "## 1.1 Número de ejemplos por tipo de clase — ¿Está balanceado?\n\nSe grafica el conteo por clase usando el dataset concatenado (`df_all`).\n",
      "metadata": {}
    },
    {
      "id": "aab1577b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "class_counts = df_all['label'].value_counts().sort_index()\nclass_names = {0: \"hate_speech\", 1: \"offensive\", 2: \"neither\"}\n\ndisplay(class_counts.rename(index=class_names).to_frame(\"count\"))\n\nplt.figure()\nplt.bar([class_names[i] for i in class_counts.index], class_counts.values)\nplt.title(\"Número de ejemplos por clase (train + test)\")\nplt.ylabel(\"Cantidad de ejemplos\")\nplt.xticks(rotation=0)\nplt.show()\n\ntotal = class_counts.sum()\nprint(\"\\nProporciones:\")\nfor k,v in class_counts.items():\n    print(f\"- {class_names[k]} ({k}): {v} ({v/total:.2%})\")\n\nprint(\"\\nComentario:\")\nprint(\"El dataset NO está balanceado: la clase 'offensive' domina ampliamente.\")",
      "outputs": []
    },
    {
      "id": "404f8e65",
      "cell_type": "markdown",
      "source": "## 1.2 Largo de las oraciones por clase (número de palabras) — ¿Hay patrones?\n\nCalculamos el número de palabras por tweet (`n_words`) y comparamos distribuciones por clase.\n",
      "metadata": {}
    },
    {
      "id": "aeb04ada",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "summary = (df_all\n           .groupby('label')['n_words']\n           .agg(['count','mean','median','std','min','max'])\n           .rename(index=class_names))\ndisplay(summary)\n\n# Boxplot por clase\ndata = [df_all.loc[df_all['label']==k, 'n_words'].values for k in [0,1,2]]\nplt.figure()\nplt.boxplot(data, labels=[class_names[k] for k in [0,1,2]], showfliers=False)\nplt.title(\"Distribución del largo (número de palabras) por clase\")\nplt.ylabel(\"Número de palabras\")\nplt.show()\n\nprint(\"Comentario:\")\nprint(\"- En este dataset, 'neither' tiende a tener oraciones un poco más largas (mayor mediana/promedio).\")\nprint(\"- 'hate_speech' y 'offensive' son muy similares en longitud, por lo que el largo por sí solo no separa bien esas clases.\")",
      "outputs": []
    },
    {
      "id": "08528d7c",
      "cell_type": "markdown",
      "source": "## 1.3 Top 40 palabras más frecuentes por clase — comentario\n\nPara cada clase:\n1) limpiamos el texto,\n2) tokenizamos,\n3) removemos stopwords,\n4) contamos frecuencias.\n\n> Se reportan las 40 palabras más frecuentes y se comenta el resultado.\n",
      "metadata": {}
    },
    {
      "id": "2477c92c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "top_words = {}\nfor k in [0,1,2]:\n    toks = []\n    for t in df_all.loc[df_all['label']==k, 'tweet']:\n        toks.extend(tokenize_words(t))\n    top_words[k] = Counter(toks).most_common(40)\n\nfor k in [0,1,2]:\n    print(f\"\\n=== Clase {k}: {class_names[k]} ===\")\n    for w,c in top_words[k]:\n        print(f\"{w:15s} {c}\")\n\nprint(\"\\nComentario (general):\")\nprint(\"- 'hate_speech' y 'offensive' comparten mucho vocabulario ofensivo, lo que puede producir confusiones.\")\nprint(\"- 'neither' incluye más palabras contextuales (p.ej. temas generales), aunque puede contener términos ofensivos también.\")\n",
      "outputs": []
    },
    {
      "id": "f53ee977",
      "cell_type": "markdown",
      "source": "## 2) Preprocesamiento del texto (y justificación)\n\nComo el objetivo es construir una matriz **TF‑IDF** y luego entrenar un clasificador clásico de ML, usamos un preprocesamiento que reduzca ruido:\n\n- **Lowercasing**: reduce duplicados (`Dog` vs `dog`).\n- Remover **URLs**, **@mentions** y entidades HTML: suelen no aportar a la semántica de clase.\n- Mantener solo letras y apóstrofes: evita tokens basura.\n- `stop_words='english'`: reduce palabras extremadamente frecuentes y poco informativas.\n- `ngram_range=(1,2)`: unigrams + bigrams capturan expresiones cortas (útiles en toxicidad/hate).\n- `min_df=2` y `max_df=0.9`: filtra términos muy raros y demasiado comunes.\n\n> En un enfoque más avanzado (Transformers), normalmente se haría mucho menos preprocesamiento y se usaría el tokenizer del modelo.\n",
      "metadata": {}
    },
    {
      "id": "3a04d5b7",
      "cell_type": "markdown",
      "source": "## 3) Construir matriz TF‑IDF (train y test) y tamaño del vocabulario\n\n- `fit` **solo** con `train`\n- `transform` para `test`\n",
      "metadata": {}
    },
    {
      "id": "3671ca1c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "vectorizer = TfidfVectorizer(\n    preprocessor=clean_text_basic,\n    stop_words='english',\n    ngram_range=(1,2),\n    min_df=2,\n    max_df=0.9\n)\n\nX_train = vectorizer.fit_transform(train['tweet'])\nX_test  = vectorizer.transform(test['tweet'])\n\nvocab_size = len(vectorizer.vocabulary_)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test  shape:\", X_test.shape)\nprint(\"Tamaño del vocabulario (train):\", vocab_size)",
      "outputs": []
    },
    {
      "id": "932ecfc9",
      "cell_type": "markdown",
      "source": "## 4) Entrenar un clasificador de Machine Learning\n\nSe entrena un **Linear SVM (LinearSVC)**, que suele funcionar bien con TF‑IDF en texto.\n\nComo el dataset está desbalanceado, usamos `class_weight='balanced'` para penalizar más los errores en clases minoritarias.\n",
      "metadata": {}
    },
    {
      "id": "d2c761fc",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "clf = LinearSVC(class_weight='balanced', random_state=42, dual=False)\nclf.fit(X_train, train['label'])\n\npred = clf.predict(X_test)\nacc = accuracy_score(test['label'], pred)\nprint(\"Accuracy (test):\", round(acc, 4))",
      "outputs": []
    },
    {
      "id": "ae81fd2e",
      "cell_type": "markdown",
      "source": "## 5) Métricas: Precision, Recall y F1-score (general y por clase)\n\nSe reportan métricas por clase y promedios macro/weighted.\n- **Macro avg**: promedia clases por igual (útil con desbalance).\n- **Weighted avg**: pondera por soporte (tiende a favorecer la clase mayoritaria).\n",
      "metadata": {}
    },
    {
      "id": "fe40acd1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "print(classification_report(\n    test['label'], pred,\n    target_names=[class_names[0], class_names[1], class_names[2]],\n    digits=4\n))\n\nprint(\"Comentario:\")\nprint(\"- Normalmente la clase minoritaria ('hate_speech') obtiene menor recall/precision.\")\nprint(\"- 'offensive' tiende a ser más fácil por su alta cantidad de ejemplos.\")\nprint(\"- Mirar macro-F1 es clave para evaluar desempeño equilibrado entre clases.\")",
      "outputs": []
    },
    {
      "id": "9b189973",
      "cell_type": "markdown",
      "source": "## 6) Matriz de confusión e interpretación\n\nLa matriz muestra:\n- Filas: clase real\n- Columnas: clase predicha\n",
      "metadata": {}
    },
    {
      "id": "38d4d996",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "cm = confusion_matrix(test['label'], pred, labels=[0,1,2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_names[0], class_names[1], class_names[2]])\n\nplt.figure()\ndisp.plot(values_format='d')\nplt.title(\"Matriz de confusión (test)\")\nplt.show()\n\nprint(\"Matriz (filas=real, cols=pred):\\n\", cm)\n\nprint(\"\\nInterpretación:\")\nprint(\"- Un error común es confundir 'hate_speech' con 'offensive' por vocabulario muy similar.\")\nprint(\"- Los aciertos altos en 'offensive' pueden inflar el accuracy debido al desbalance.\")\n",
      "outputs": []
    }
  ]
}